{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XIwLZB2_fRot",
        "outputId": "ec000295-cae2-4ef3-e1ad-ebaeb362b558"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data generated and saved to outputs/synthetic_multivariate.csv\n",
            "Supervised shapes: (1427, 60, 3) (1427, 14)\n",
            "Starting walk-forward CV (this may take a few minutes)...\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "Fold 0 | train_end=713 | val_end=891 | RMSE=3.1366 MAE=2.6091\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "Fold 1 | train_end=891 | val_end=1069 | RMSE=2.0985 MAE=1.7162\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 13 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7c18b95cba60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "Fold 2 | train_end=1069 | val_end=1247 | RMSE=2.8013 MAE=2.3495\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 13 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7c18b9149f80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "Fold 3 | train_end=1247 | val_end=1425 | RMSE=1.7446 MAE=1.4677\n",
            "Cross-validation metrics saved to outputs/cv_metrics.json\n",
            "Epoch 1/30\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 744.4200\n",
            "Epoch 2/30\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 253.7194\n",
            "Epoch 3/30\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 33.8574\n",
            "Epoch 4/30\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 28.4157\n",
            "Epoch 5/30\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 21.6114\n",
            "Epoch 6/30\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - loss: 11.9262\n",
            "Epoch 7/30\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 9.1465\n",
            "Epoch 8/30\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 7.9413\n",
            "Epoch 9/30\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 7.8836\n",
            "Epoch 10/30\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 7.7644\n",
            "Epoch 11/30\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 7.5930\n",
            "Epoch 12/30\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 6.7829\n",
            "Epoch 13/30\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 7.8207\n",
            "Epoch 14/30\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 6.8107\n",
            "Epoch 15/30\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 7.1921\n",
            "Epoch 16/30\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 6.6204\n",
            "Epoch 17/30\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 6.9401\n",
            "Epoch 18/30\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 7.3741\n",
            "Epoch 19/30\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 6.8299\n",
            "Epoch 20/30\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 6.6974\n",
            "Epoch 21/30\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 6.6015\n",
            "Epoch 22/30\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 6.6037\n",
            "Epoch 23/30\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 6.8247\n",
            "Epoch 24/30\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 6.4899\n",
            "Epoch 25/30\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - loss: 6.2360\n",
            "Epoch 26/30\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 6.3852\n",
            "Epoch 27/30\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 6.0072\n",
            "Epoch 28/30\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 6.3067\n",
            "Epoch 29/30\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 6.2911\n",
            "Epoch 30/30\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 6.2401\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step\n",
            "Final forecast saved to outputs/final_forecast.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/shap/explainers/_deep/deep_tf.py:94: UserWarning: Your TensorFlow version is newer than 2.4.0 and so graph support has been removed in eager mode and some static graphs may not be supported. See PR #1483 for discussion.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/keras/src/models/functional.py:241: UserWarning: The structure of `inputs` doesn't match the expected structure.\n",
            "Expected: keras_tensor_20\n",
            "Received: inputs=['Tensor(shape=(200, 60, 3))']\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.12/dist-packages/keras/src/models/functional.py:241: UserWarning: The structure of `inputs` doesn't match the expected structure.\n",
            "Expected: keras_tensor_20\n",
            "Received: inputs=['Tensor(shape=(400, 60, 3))']\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SHAP DeepExplainer failed with error: in user code:\n",
            "\n",
            "    File \"/usr/local/lib/python3.12/dist-packages/shap/explainers/_deep/deep_tf.py\", line 265, in grad_graph  *\n",
            "        x_grad = tape.gradient(out, shap_rAnD)\n",
            "\n",
            "    LookupError: gradient registry has no entry for: shap_TensorListStack\n",
            "\n",
            "You can try KernelExplainer (slower) or use Tree-based models for faster SHAP.\n",
            "All outputs written to the outputs/ folder.\n",
            "Reference image (uploaded by you) path: /mnt/data/WhatsApp Image 2025-11-20 at 8.48.29 AM.jpeg\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "main.py\n",
        "Time-Series Forecasting Project: LSTM (multivariate) + Walk-forward CV + SHAP explainability\n",
        "Generates synthetic multivariate data (3 interacting features), trains an LSTM for multi-step forecasts,\n",
        "runs walk-forward validation, computes RMSE/MAE, and produces SHAP explainability outputs.\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Input, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import shap\n",
        "import joblib\n",
        "import json\n",
        "\n",
        "# -------------------------\n",
        "# Configuration\n",
        "# -------------------------\n",
        "RANDOM_SEED = 42\n",
        "np.random.seed(RANDOM_SEED)\n",
        "tf.random.set_seed(RANDOM_SEED)\n",
        "\n",
        "OUT_DIR = \"outputs\"\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "\n",
        "LOOKBACK = 60       # how many past timesteps used as input\n",
        "HORIZON = 14        # multi-step forecast horizon\n",
        "N_FEATURES = 3      # number of features (multivariate)\n",
        "EPOCHS = 30\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# -------------------------\n",
        "# 1) Synthetic multivariate dataset (3 interacting features)\n",
        "# -------------------------\n",
        "def generate_multivariate_series(n_days=1500):\n",
        "    t = np.arange(n_days)\n",
        "    # Base trend\n",
        "    trend = 0.01 * t\n",
        "    # Seasonal component (yearly-like) and weekly-like\n",
        "    season_year = 5.0 * np.sin(2 * np.pi * t / 365.0)\n",
        "    season_week = 2.0 * np.sin(2 * np.pi * t / 7.0)\n",
        "    # Random noise\n",
        "    noise = np.random.normal(0, 0.8, size=n_days)\n",
        "\n",
        "    # Feature 1: main target signal (combination of trend + season + noise)\n",
        "    y = 20 + trend + season_year + season_week + noise\n",
        "\n",
        "    # Feature 2: interacting regressor correlated with monthly cycles and lagged influence\n",
        "    reg1 = 3.0 * np.sin(2 * np.pi * t / 30.0) + 0.5 * np.roll(y, 7) * 0.01\n",
        "    reg1 += np.random.normal(0, 0.3, n_days)\n",
        "\n",
        "    # Feature 3: exogenous signal that sometimes spikes (simulates promotions / events)\n",
        "    spikes = np.zeros(n_days)\n",
        "    spike_indices = np.random.choice(np.arange(50, n_days-1, 50), size=int(n_days/300)+1, replace=False)\n",
        "    spikes[spike_indices] = np.random.uniform(5, 12, size=len(spike_indices))\n",
        "    reg2 = 1.5 * np.cos(2 * np.pi * t / 90.0) + spikes + np.random.normal(0, 0.4, n_days)\n",
        "\n",
        "    df = pd.DataFrame({\n",
        "        \"ds\": pd.date_range(\"2015-01-01\", periods=n_days, freq=\"D\"),\n",
        "        \"y\": y,\n",
        "        \"reg1\": reg1,\n",
        "        \"reg2\": reg2\n",
        "    })\n",
        "    return df\n",
        "\n",
        "df = generate_multivariate_series(n_days=1500)\n",
        "df.to_csv(os.path.join(OUT_DIR, \"synthetic_multivariate.csv\"), index=False)\n",
        "print(\"Data generated and saved to outputs/synthetic_multivariate.csv\")\n",
        "\n",
        "# -------------------------\n",
        "# 2) Supervised framing: create sliding windows\n",
        "# -------------------------\n",
        "def create_supervised(df, lookback=LOOKBACK, horizon=HORIZON, features=[\"y\",\"reg1\",\"reg2\"]):\n",
        "    X, Y = [], []\n",
        "    df_vals = df[features].values\n",
        "    n = len(df_vals)\n",
        "    for i in range(lookback, n - horizon + 1):\n",
        "        past = df_vals[i-lookback:i, :]   # shape (lookback, n_features)\n",
        "        future = df_vals[i:i+horizon, 0]  # target 'y' next horizon\n",
        "        X.append(past)\n",
        "        Y.append(future)\n",
        "    X = np.array(X)  # (samples, lookback, features)\n",
        "    Y = np.array(Y)  # (samples, horizon)\n",
        "    return X, Y\n",
        "\n",
        "features = [\"y\",\"reg1\",\"reg2\"]\n",
        "X, Y = create_supervised(df, LOOKBACK, HORIZON, features=features)\n",
        "print(\"Supervised shapes:\", X.shape, Y.shape)\n",
        "\n",
        "# -------------------------\n",
        "# 3) Walk-forward cross-validation (rolling forecast origin)\n",
        "# -------------------------\n",
        "def build_lstm_model(lookback, n_features, horizon):\n",
        "    model = Sequential([\n",
        "        Input(shape=(lookback, n_features)),\n",
        "        LSTM(64, return_sequences=False),\n",
        "        Dropout(0.2),\n",
        "        Dense(64, activation=\"relu\"),\n",
        "        Dense(horizon)   # multi-step output\n",
        "    ])\n",
        "    model.compile(optimizer=Adam(learning_rate=0.001), loss=\"mse\")\n",
        "    return model\n",
        "\n",
        "def walk_forward_cv(X, Y, n_splits=5, initial_train_fraction=0.5):\n",
        "    n_samples = X.shape[0]\n",
        "    initial_train = int(n_samples * initial_train_fraction)\n",
        "    fold_size = (n_samples - initial_train) // n_splits\n",
        "    metrics = []\n",
        "    preds_all = []\n",
        "    trues_all = []\n",
        "    models = []\n",
        "\n",
        "    for fold in range(n_splits):\n",
        "        train_end = initial_train + fold * fold_size\n",
        "        val_end = train_end + fold_size\n",
        "        if val_end > n_samples:\n",
        "            val_end = n_samples\n",
        "\n",
        "        X_train = X[:train_end]\n",
        "        Y_train = Y[:train_end]\n",
        "        X_val = X[train_end:val_end]\n",
        "        Y_val = Y[train_end:val_end]\n",
        "\n",
        "        if len(X_val) == 0:\n",
        "            break\n",
        "\n",
        "        model = build_lstm_model(LOOKBACK, N_FEATURES, HORIZON)\n",
        "        model.fit(X_train, Y_train, epochs=EPOCHS, batch_size=BATCH_SIZE, verbose=0)\n",
        "        Y_pred = model.predict(X_val)\n",
        "        # compute metrics per-fold (flatten over horizon)\n",
        "        rmse = np.sqrt(mean_squared_error(Y_val.flatten(), Y_pred.flatten()))\n",
        "        mae = mean_absolute_error(Y_val.flatten(), Y_pred.flatten())\n",
        "\n",
        "        metrics.append({\"fold\": fold, \"rmse\": float(rmse), \"mae\": float(mae)})\n",
        "        preds_all.append(Y_pred)\n",
        "        trues_all.append(Y_val)\n",
        "        models.append(model)\n",
        "        print(f\"Fold {fold} | train_end={train_end} | val_end={val_end} | RMSE={rmse:.4f} MAE={mae:.4f}\")\n",
        "\n",
        "    return metrics, preds_all, trues_all, models\n",
        "\n",
        "print(\"Starting walk-forward CV (this may take a few minutes)...\")\n",
        "metrics, preds_all, trues_all, models = walk_forward_cv(X, Y, n_splits=4, initial_train_fraction=0.5)\n",
        "\n",
        "# Save metrics\n",
        "with open(os.path.join(OUT_DIR,\"cv_metrics.json\"), \"w\") as f:\n",
        "    json.dump(metrics, f, indent=2)\n",
        "print(\"Cross-validation metrics saved to outputs/cv_metrics.json\")\n",
        "\n",
        "# -------------------------\n",
        "# 4) Select final model (last trained model) and do full training on all available training data\n",
        "# -------------------------\n",
        "final_model = build_lstm_model(LOOKBACK, N_FEATURES, HORIZON)\n",
        "final_model.fit(X[:-HORIZON], Y[:-HORIZON], epochs=EPOCHS, batch_size=BATCH_SIZE, verbose=1)\n",
        "final_model.save(os.path.join(OUT_DIR, \"final_lstm_model.keras\"))\n",
        "joblib.dump({\"config\": {\"LOOKBACK\": LOOKBACK, \"HORIZON\": HORIZON, \"features\": features}}, os.path.join(OUT_DIR, \"meta.joblib\"))\n",
        "\n",
        "# -------------------------\n",
        "# 5) Forecast final horizon on last available window and visualize\n",
        "# -------------------------\n",
        "last_input = X[-1:]  # most recent lookback window\n",
        "pred_final = final_model.predict(last_input)[0]  # shape (HORIZON,)\n",
        "dates_future = pd.date_range(df[\"ds\"].iloc[-1] + pd.Timedelta(days=1), periods=HORIZON, freq=\"D\")\n",
        "forecast_df = pd.DataFrame({\"ds\": dates_future, \"yhat\": pred_final})\n",
        "forecast_df.to_csv(os.path.join(OUT_DIR, \"final_forecast.csv\"), index=False)\n",
        "print(\"Final forecast saved to outputs/final_forecast.csv\")\n",
        "\n",
        "# Plot last test actual vs predicted (use last available val set)\n",
        "# We'll compare the final predicted horizon vs actuals (if available in data)\n",
        "actual_future = df[\"y\"].iloc[-HORIZON:].values\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.plot(dates_future, pred_final, label=\"Forecast (pred)\")\n",
        "plt.plot(df[\"ds\"].iloc[-HORIZON:], actual_future, label=\"Actual (last HORIZON days)\")\n",
        "plt.legend()\n",
        "plt.title(\"Final multi-step forecast vs actual (last available window)\")\n",
        "plt.savefig(os.path.join(OUT_DIR, \"forecast_vs_actual.png\"))\n",
        "plt.close()\n",
        "\n",
        "# -------------------------\n",
        "# 6) SHAP explainability (DeepExplainer for Keras LSTM)\n",
        "# -------------------------\n",
        "# DeepExplainer requires a background sample; use a small subset of training data\n",
        "background = X[:200] if X.shape[0] > 200 else X[:max(1, X.shape[0]//4)]\n",
        "# Use the model's prediction function wrapper for shap\n",
        "# For DeepExplainer, inputs must be a list matching model inputs; we have single 3D input\n",
        "try:\n",
        "    explainer = shap.DeepExplainer(final_model, background)\n",
        "    # compute SHAP values for the last N samples used for explanation\n",
        "    to_explain = X[-200:] if X.shape[0] >= 200 else X[-20:]\n",
        "    shap_values = explainer.shap_values(to_explain)  # shap_values is a list (one per model output)\n",
        "    # For multi-output (HORIZON outputs), shap_values is a list of arrays (each: samples, lookback, features)\n",
        "    # We'll summarize by averaging across horizon outputs and across lookback timesteps for each feature\n",
        "    # Convert to feature-level importances\n",
        "    # shap_values_per_output -> list of arrays shape (samples, lookback, features)\n",
        "    mean_abs_per_feature = None\n",
        "    for out_idx, arr in enumerate(shap_values):\n",
        "        # arr: (samples, lookback, features)\n",
        "        # take mean absolute across samples and lookback -> (features,)\n",
        "        abs_mean = np.mean(np.abs(arr), axis=(0,1))\n",
        "        if mean_abs_per_feature is None:\n",
        "            mean_abs_per_feature = abs_mean\n",
        "        else:\n",
        "            mean_abs_per_feature += abs_mean\n",
        "    mean_abs_per_feature = mean_abs_per_feature / len(shap_values)\n",
        "    # Save importance to JSON\n",
        "    fi = {feat: float(val) for feat,val,feat in zip(mean_abs_per_feature, mean_abs_per_feature, features)}\n",
        "    # The above zip is not correct; instead map properly:\n",
        "    fi = {features[i]: float(mean_abs_per_feature[i]) for i in range(len(features))}\n",
        "    with open(os.path.join(OUT_DIR, \"shap_feature_importance.json\"), \"w\") as f:\n",
        "        json.dump(fi, f, indent=2)\n",
        "\n",
        "    # Plot a simple bar chart of mean abs importance\n",
        "    plt.figure(figsize=(6,3))\n",
        "    plt.bar(features, mean_abs_per_feature)\n",
        "    plt.title(\"Mean |SHAP value| per feature (averaged across horizon & timesteps)\")\n",
        "    plt.ylabel(\"mean(|SHAP|)\")\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(OUT_DIR, \"shap_feature_importance.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    # Save one SHAP summary image (we'll aggregate inputs by taking mean across lookback)\n",
        "    # Prepare tabular background for plotting: average each sample across lookback to get (samples, features)\n",
        "    tab_X = np.mean(to_explain, axis=1)  # (samples, features)\n",
        "    # Build aggregated shap values similarly (average across lookback)\n",
        "    shap_vals_agg = np.mean(np.stack([np.mean(arr, axis=1) for arr in shap_values], axis=0), axis=0)\n",
        "    # shap_vals_agg shape (samples, features)\n",
        "    shap.summary_plot(shap_vals_agg, tab_X, show=False)\n",
        "    plt.savefig(os.path.join(OUT_DIR, \"shap_summary_aggregated.png\"))\n",
        "    plt.close()\n",
        "    print(\"SHAP explainability outputs saved to outputs folder.\")\n",
        "except Exception as e:\n",
        "    print(\"SHAP DeepExplainer failed with error:\", e)\n",
        "    print(\"You can try KernelExplainer (slower) or use Tree-based models for faster SHAP.\")\n",
        "    with open(os.path.join(OUT_DIR,\"shap_error.txt\"), \"w\") as f:\n",
        "        f.write(str(e))\n",
        "\n",
        "# -------------------------\n",
        "# 7) Save basic report and metrics summary\n",
        "# -------------------------\n",
        "summary = {\n",
        "    \"cv_metrics\": metrics,\n",
        "    \"final_forecast_sample\": pred_final.tolist()[:min(10,len(pred_final))],\n",
        "    \"final_model_path\": os.path.join(OUT_DIR, \"final_lstm_model.keras\")\n",
        "}\n",
        "with open(os.path.join(OUT_DIR, \"summary.json\"), \"w\") as f:\n",
        "    json.dump(summary, f, indent=2)\n",
        "\n",
        "print(\"All outputs written to the outputs/ folder.\")\n",
        "print(\"Reference image (uploaded by you) path:\", \"/mnt/data/WhatsApp Image 2025-11-20 at 8.48.29 AM.jpeg\")\n"
      ]
    }
  ]
}